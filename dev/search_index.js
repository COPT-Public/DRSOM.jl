var documenterSearchIndex = {"docs":
[{"location":"api/#api_reference_list","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DRSOM.DRSOMIteration","category":"page"},{"location":"api/#DRSOM.DRSOMIteration","page":"API Reference","title":"DRSOM.DRSOMIteration","text":"Iteration object for DRSOM\n\n\n\n\n\n","category":"type"},{"location":"#DRSOM.jl","page":"Home","title":"DRSOM.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DRSOM.jl is a Julia implementation of the Dimension-Reduced Second-Order Method for unconstrained smooth optimization. The DRSOM works with the following iteration:","category":"page"},{"location":"","page":"Home","title":"Home","text":"        x_k+1     = x_k- alpha_k^1 g_k +alpha_k^2 d_k ","category":"page"},{"location":"","page":"Home","title":"Home","text":"where  m_k^alpha(alpha) is a 2-dimensional quadratic approximation to f(x) using gradient g_k and Hessian information H_k, namely,","category":"page"},{"location":"","page":"Home","title":"Home","text":"  beginaligned\n    min_alpha inmathbbR^2 m_k(alpha) = f(x_k) + (c_k)^T alpha+frac12 alpha^T Q_k alpha\n    mathrmst alpha_G_k= sqrtalpha^T G_k alpha le Delta quad textrmwithquad G_k=leftbeginarraycc\nleft(g_kright)^T g_k  -left(g_kright)^T d_k \n-left(g_kright)^T d_k  left(d_kright)^T d_k\nendarrayright   \n  endaligned ","category":"page"},{"location":"","page":"Home","title":"Home","text":"and","category":"page"},{"location":"","page":"Home","title":"Home","text":"\nQ_k =beginbmatrix\n\t( g_k)^T H_k g_k   -( d_k)^T H_k g_k \n\t-( d_k)^T H_k g_k  ( d_k)^T H_k d_k\n\tendbmatrix in mathcal S^2 \nc_k =beginbmatrix\n\t-left g_kright^2 \n\t( g_k)^T d_k\n\tendbmatrix in mathbbR^2","category":"page"},{"location":"","page":"Home","title":"Home","text":"The differentiation is done by ForwardDiff and ReverseDiff \nThe subproblem is very easy to solve.","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: Note\nNotably, DRSOM does not have to compute n-by-n Hessian H_k directly (of course, it is perfect if you can provide!). Instead, it requires Hessian-vector products (HVPs) or interpolation to contruct the quadratic model. The latter approach is now preferred.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DRSOM.jl is now a suite of algorithms, including the variants of original DRSOM and the HSODM: a Homogeneous Second-order Descent Method.","category":"page"},{"location":"#Install-DRSOM.jl","page":"Home","title":"Install DRSOM.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"tip: Tip\nTo try your own ideas with DRSOM.jl,  use local path mode:(v1.8) pkg> add path-to-DRSOM.jlor the dev command:(v1.8) pkg> dev DRSOM","category":"page"},{"location":"#API-Reference","page":"Home","title":"API Reference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you just want help on a specific function, see the API Reference page.","category":"page"},{"location":"#Known-issues","page":"Home","title":"Known issues","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DRSOM.jl is still under active development. Please add issues on GitHub.","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DRSOM.jl is licensed under the MIT License. Check LICENSE for more details","category":"page"},{"location":"#Acknowledgment","page":"Home","title":"Acknowledgment","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Special thanks go to the COPT team and Tianyi Lin (Darren) for helpful suggestions.","category":"page"},{"location":"#Developer","page":"Home","title":"Developer","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Chuwen Zhang <chuwzhang@gmail.com>\nYinyu Ye     <yyye@stanford.edu>","category":"page"},{"location":"#Reference","page":"Home","title":"Reference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You are welcome to cite our paper on DRSOM :)","category":"page"},{"location":"","page":"Home","title":"Home","text":"\n@misc{zhang_drsom_2022,\n\ttitle = {{DRSOM}: {A} {Dimension} {Reduced} {Second}-{Order} {Method} and {Preliminary} {Analyses}},\n\tcopyright = {All rights reserved},\n\tshorttitle = {{DRSOM}},\n\turl = {http://arxiv.org/abs/2208.00208},\n\tlanguage = {en},\n\turldate = {2022-08-12},\n\tpublisher = {arXiv},\n\tauthor = {Zhang, Chuwen and Ge, Dongdong and Jiang, Bo and Ye, Yinyu},\n\tmonth = jul,\n\tyear = {2022},\n\tnote = {arXiv:2208.00208 [cs, math]},\n\tkeywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"and HSODM,","category":"page"},{"location":"","page":"Home","title":"Home","text":"@misc{zhang_homogenous_2022,\n\ttitle = {A {Homogenous} {Second}-{Order} {Descent} {Method} for {Nonconvex} {Optimization}},\n\turl = {http://arxiv.org/abs/2211.08212},\n\turldate = {2022-11-16},\n\tpublisher = {arXiv},\n\tauthor = {Zhang, Chuwen and Ge, Dongdong and He, Chang and Jiang, Bo and Jiang, Yuntian and Xue, Chenyu and Ye, Yinyu},\n\tmonth = nov,\n\tyear = {2022},\n\tnote = {arXiv:2211.08212 [math]},\n\tkeywords = {Mathematics - Optimization and Control}\n}","category":"page"}]
}
