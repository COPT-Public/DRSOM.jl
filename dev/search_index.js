var documenterSearchIndex = {"docs":
[{"location":"api/#api_reference_list","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Original-DRSOM-with-2-directions-g_k-and-d_k","page":"API Reference","title":"Original DRSOM with 2 directions g_k and d_k","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DRSOM.DRSOMIteration","category":"page"},{"location":"api/#DRSOM.DRSOMIteration","page":"API Reference","title":"DRSOM.DRSOMIteration","text":"Iteration object for DRSOM, to initialize an iterator,      you must specify the attributes, including \n\nattr notes\nx0 initial point\nf the smooth function to minimize\nϕ the nonsmooth function\ng the gradient function\nga gradient function via forward or backward diff\nhvp hvp function via forward or backward diff\nH hessian function\n\nrest of the attributes have default options:\n\n    t::Dates.DateTime = Dates.now()\n    itermax::Int64 = 20\n    fog = :forward\n    sog = :forward\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API Reference","title":"API Reference","text":"note: Note\nWe do not currently support nonsmooth optimization, this is a future plan.","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DRSOM.DRSOMState","category":"page"},{"location":"api/#DRSOM.DRSOMState","page":"API Reference","title":"DRSOM.DRSOMState","text":"State struct for DRSOM to keep the iterate information, We keep the following attributes:\n\nattr notes\nx::Tx iterate\nfx::R new value f at x: x(k)\nfz::R old value f at z: x(k-1)\n∇f::Tx gradient of f at x\n∇fz::Tx gradient of f at z\n∇hvp::Tx gradient buffer (for buffer use of hvps)\ny::Tx forward point\nz::Tx previous point\nd::Tx momentum/fixed-point diff at iterate (= x - z)\nα₁::R stepsize 1 parameter of gradient\nα₂::R stepsize 2 parameter of momentum\nQ::Tq Q for low-dimensional QP\nc::Tc c for low-dimensional QP\nG::Tq c for low-dimensional QP\nΔ::R trs radius\ndq::R decrease of estimated quadratic model\ndf::R decrease of the real function value\nρ::R trs descrease ratio: ρ = df/dq\nϵ::R eps: residual for gradient\nγ::R scaling parameter γ for λ\nψ::R 1-D linear search iteration\nλ::R dual λ\nkₜ::Int inner iterations for adjustment\nkf::Int function evaluations\nkg::Int gradient evaluations\nkh::Int hvp      evaluations\nkH::Int hessian  evaluations\nt::R running time\n\n\n\n\n\n","category":"type"},{"location":"#DRSOM.jl","page":"Home","title":"DRSOM.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DRSOM.jl is a Julia implementation of the Dimension-Reduced Second-Order Method for unconstrained smooth optimization. The DRSOM works with the following iteration:","category":"page"},{"location":"","page":"Home","title":"Home","text":"        x_k+1     = x_k- alpha_k^1 g_k +alpha_k^2 d_k ","category":"page"},{"location":"","page":"Home","title":"Home","text":"where  m_k^alpha(alpha) is a 2-dimensional quadratic approximation to f(x) using gradient g_k and Hessian information H_k, namely,","category":"page"},{"location":"","page":"Home","title":"Home","text":"  beginaligned\n    min_alpha inmathbbR^2 m_k(alpha) = f(x_k) + (c_k)^T alpha+frac12 alpha^T Q_k alpha\n    mathrmst alpha_G_k= sqrtalpha^T G_k alpha le Delta quad textrmwithquad G_k=leftbeginarraycc\nleft(g_kright)^T g_k  -left(g_kright)^T d_k \n-left(g_kright)^T d_k  left(d_kright)^T d_k\nendarrayright   \n  endaligned ","category":"page"},{"location":"","page":"Home","title":"Home","text":"and","category":"page"},{"location":"","page":"Home","title":"Home","text":"\nQ_k =beginbmatrix\n\t( g_k)^T H_k g_k   -( d_k)^T H_k g_k \n\t-( d_k)^T H_k g_k  ( d_k)^T H_k d_k\n\tendbmatrix in mathcal S^2 \nc_k =beginbmatrix\n\t-left g_kright^2 \n\t( g_k)^T d_k\n\tendbmatrix in mathbbR^2","category":"page"},{"location":"","page":"Home","title":"Home","text":"The differentiation is done by ForwardDiff and ReverseDiff \nThe subproblem is very easy to solve.","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: Note\nNotably, DRSOM does not have to compute n-by-n Hessian H_k directly (of course, it is perfect if you can provide!). Instead, it requires Hessian-vector products (HVPs) or interpolation to contruct the quadratic model. The latter approach is now preferred.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DRSOM.jl is now a suite of algorithms, including the variants of original DRSOM and the HSODM: a Homogeneous Second-order Descent Method.","category":"page"},{"location":"#Install-DRSOM.jl","page":"Home","title":"Install DRSOM.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"tip: Tip\nTo try your own ideas with DRSOM.jl,  use local path mode:(v1.8) pkg> add path-to-DRSOM.jlor the dev command:(v1.8) pkg> dev DRSOM","category":"page"},{"location":"#API-Reference","page":"Home","title":"API Reference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you just want help on a specific function, see the API Reference page.","category":"page"},{"location":"#Known-issues","page":"Home","title":"Known issues","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DRSOM.jl is still under active development. Please add issues on GitHub.","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DRSOM.jl is licensed under the MIT License. Check LICENSE for more details","category":"page"},{"location":"#Acknowledgment","page":"Home","title":"Acknowledgment","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Special thanks go to the COPT team and Tianyi Lin (Darren) for helpful suggestions.","category":"page"},{"location":"#Developer","page":"Home","title":"Developer","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Chuwen Zhang <chuwzhang@gmail.com>\nYinyu Ye     <yyye@stanford.edu>","category":"page"},{"location":"#Reference","page":"Home","title":"Reference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You are welcome to cite our paper on DRSOM :)","category":"page"},{"location":"","page":"Home","title":"Home","text":"@misc{zhang_drsom_2022,\n\ttitle = {{DRSOM}: {A} {Dimension} {Reduced} {Second}-{Order} {Method} and {Preliminary} {Analyses}},\n\turl = {http://arxiv.org/abs/2208.00208},\n\tpublisher = {arXiv},\n\tauthor = {Zhang, Chuwen and Ge, Dongdong and Jiang, Bo and Ye, Yinyu},\n\tmonth = jul,\n\tyear = {2022},\n\tnote = {arXiv:2208.00208 [cs, math]},\n\tkeywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"and HSODM,","category":"page"},{"location":"","page":"Home","title":"Home","text":"@misc{zhang_homogenous_2022,\n\ttitle = {A {Homogenous} {Second}-{Order} {Descent} {Method} for {Nonconvex} {Optimization}},\n\turl = {http://arxiv.org/abs/2211.08212},\n\tpublisher = {arXiv},\n\tauthor = {Zhang, Chuwen and Ge, Dongdong and He, Chang and Jiang, Bo and Jiang, Yuntian and Xue, Chenyu and Ye, Yinyu},\n\tmonth = nov,\n\tyear = {2022},\n\tnote = {arXiv:2211.08212 [math]},\n\tkeywords = {Mathematics - Optimization and Control}\n}","category":"page"}]
}
